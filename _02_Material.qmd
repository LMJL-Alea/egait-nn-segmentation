# Material {#sec-material}

In this work, the objective is to detect right and left heel strike and toe off events from hip orientation data over time. Knowledge of the occurences of these events is critical to compute key gait parameters such as the mean and the variability of stride duration, metrics of asymmetry or ratio stance/swing which have been proven to be clinically relevant [@annweiler2009risk;@beauchet2016poor]. We propose to address this problem by training, tuning and comparing several supervised classification models. In details, we consider the timepoints as the statistical units (observations) and we aim at training models to affect a *label* to each of them. This requires to elaborate a *labelled gait data* set in which we know which timepoints correspond to the occurence of the key gait events.

For this purpose, we used two sources of data. First, we clipped a 9-axis inertial measurement unit (IMU) at the level of the right hip and measured its orientation (that we assimilate to the hip orientation) over time during walking sessions. The data is recorded in the form of a unit quaternion time series. @sec-quaternions provides a brief overview of unit quaternions and their properties. Second, we used a pressure-sensitive walkway (GAITRite® mat) as a gold standard to record the occurences of the gait events of interest. @sec-data-acquisition elicits the data acquisition protocol while @sec-data-sets summarizes the two collected data sets and the elaboration of the final labelled data set. Finally, @sec-feature-space details the feature space that we constructed from the raw data to feed our machine learning models.

## Unit quaternions {#sec-quaternions}

Unit quaternions can be used to represent the 3D rotation of an object over time [@hamilton1844;@voight2021quaternion]. This representation has several advantages such as being the most compressed representation of rotation and avoiding the gimbal lock issue. We therefore chose to measure the sensor orientation as a unit quaternion.

Quaternions are four-dimensional vectors denoted by $\mathbf{q} = \left( q_w, q_x, q_y, q_z \right)$, but can also be viewed as hypercomplex numbers of rank $4$. Unit quaternions have a norm of $1$ and encode a 3D rotation with rotation angle $\theta \in [0, 2\pi]$ and rotation axis $\mathbf{u} = (u_x, u_y, u_z) \in S^2$, where $S^2$ is the 2-sphere, using the following formula:

$$
\mathbf{q} = \left( q_w, q_x, q_y, q_z \right)
= \cos \left( \frac{\theta}{2} \right) + \left( u_x i + u_y j + u_z k \right) \cdot \sin \left( \frac{\theta}{2} \right),
$$ {#eq-quaternions}

where $i$, $j$, and $k$ generalize the imaginary number $i$ and are such that $i^2 = j^2 = k^2 = ijk = -1$. Note that it is straightforward to show quaternions define through @eq-quaternions have unit norm.

The set of unit quaternions, denoted by $\mathbb{H}_u$, has a number of interesting properties. First, the quaternions $\mathbf{q}$ and $-\mathbf{q}$ represent the same rotation making $\mathbb{H}_u$ a double coverage of the space $\mathrm{SO}_3(\mathbb{R})$ of 3D rotations. Also, $\mathbb{H}_u$ forms a Lie group which is a group and a differentiable Riemannian manifold. As a group, it is in particular equipped with an identity element $\mathbf{q}^{(0)} = (1,0,0,0)$ which corresponds to the identity rotation, such that, for any $\mathbf{q} \in \mathbb{H}_u$, we have $\mathbf{q} \mathbf{q}^{(0)} = \mathbf{q}^{(0)}\mathbf{q} = \mathbf{q}$ and with a composition law $\circ$ given by the Hamilton product:

$$
\begin{aligned}
\mathbf{q}_1 \circ \mathbf{q}_2 = ( &q_{1w} q_{2w} - q_{1x} q_{2x} - q_{1y} q_{2y} - q_{1z} q_{2z}, \\
&q_{1w} q_{2x} + q_{1x} q_{2w} + q_{1y} q_{2z} - q_{1z} q_{2y}, \\
&q_{1w} q_{2y} - q_{1x} q_{2z} + q_{1y} q_{2w} + q_{1z} q_{2x}, \\
&q_{1w} q_{2z} + q_{1x} q_{2y} - q_{1y} q_{2x} + q_{1z} q_{2w}).
\end{aligned}
$$ {#eq-hamilton-product}

This is known as quaternion multiplication and, for simplicity, the symbol $\circ$ is often omitted and we simply write $\mathbf{q}_1 \mathbf{q}_2$. Note that the composition law is not commutative. As such, $\mathbb{H}_u$ is an Abelian group. The inverse of a unit quaternion $\mathbf{q}$ is given by its conjugate $\mathbf{q}^{-1} = \mathbf{q}^\star = (q_w, -q_x, -q_y, -q_z)$.

As a differentiable Riemannian manifold, it is also equipped with a natural distance, known as the *geodesic distance*, that can be used to measure the distance between two unit quaternions. For any two quaternions $\mathbf{q}_1$ and $\mathbf{q}_2$, it reads:

$$
d_g \left( \mathbf{q}_1, \mathbf{q}_2 \right) = \left\| \ln \left( \mathbf{q}_1^{-1} \mathbf{q}_2 \right) \right\| = \arccos \left( 2 \left( \mathbf{q}_1 \cdot \mathbf{q}_2 \right)^2 -1 \right),
$$ {#eq-geodesic-distance}

where the unit quaternion logarithm is defined as $\ln(\mathbf{q}) = \mathbf{u} \dfrac{\theta}{2}$.

In our application, the sensor orientation is the rotation between the reference frame of origin, here the Earth's reference frame $R_f=(f_1, f_2, f_3)$ and its own reference frame $R_s=(s_1, s_2, s_3)$ formed by the accelerometer, gyroscope, and magnetometer (see @fig-sensor-axis).

![Sensor reference and axis. [@drouin2023semi]](images/sensor-axis.png){#fig-sensor-axis width=200}

A *quaternion time series* (QTS) is an ordered set $\mathbf{Q}$ of unit quaternions along a temporal grid $t_1 < t_2 < \dots < t_p$. We will denote by $\mathbf{q}_{j} = \mathbf{Q}(t_j)$ the unit quaternion of the QTS $\mathbf{Q}$ recorded at time $t_j$. In our application, it represents the orientation of the hip at that time.

## Data acquisition {#sec-data-acquisition}

We used an IMU sensor to record the hip orientation over time. The IMU was composed of a 3-axis accelerometer, a 3-axis gyroscope and a 3-axis magnetometer. Subjects were wearing the sensor on their right hip (see @fig-sensor-position). The frequency of the sensor is $100$ Hz which corresponds to recording its orientation every $10$ ms. With this device, the data acquired is in the form of unit QTS as presented in @sec-quaternions.

![Sensor positionned on the right hip.](images/sensor-position.png){#fig-sensor-position width=150}

We asked the participants to walk on the GAITRite® mat, a gold standard in gait analysis [@Menz2004] while wearing the IMU sensor on their right hip. This choice, required to have a labeling of gait events from the walkway, constrained the path followed by the participants to a straight line of approximately nine meters. The GAITRite® device gives various information thanks to pressure sensors contained in the mat such as the time points where the subject feet touch and leave the ground at each step, which are exactly the gait events of interest to train our segmentation models for the IMU sensor. To use the two devices simultaneously, they were started at the same time by the same person with their two index fingers, allowing a good synchronization between devices [@de1992stability]. Also, we asked the participants to wait for three seconds before starting to walk on the mat to ensure that the sensor was properly calibrated and stable before walking.

We included six subjects in this study (three men and three women) of different ages and walking at different speeds to have a variety of gait data. @tbl-subjects summarized the demographic characteristics of the participants. We recorded a total of 174 walking sessions between June and September 2024. The data has been publicly released [@bellanger_2026_18222246]. We can therefore download it and store it in an R object for use in the rest of this document.

```{r}
#| label: tbl-subjects
#| tbl-cap: "Summary of subjects and walking speeds used to train the model."
#| tbl-pos: "H"
bhg <- readRDS(url(
  "https://zenodo.org/records/18222246/files/bellier_healthy_gait.rds?download=1"
))

bhg |>
  dplyr::group_by(subject, gender, age, condition) |>
  dplyr::summarise(speed = round(mean(speed), digits = 0), .groups = "drop") |>
  tidyr::pivot_wider(names_from = condition, values_from = speed) |>
  janitor::clean_names() |>
  dplyr::select(
    id = subject,
    gender,
    age,
    slow,
    intermediate,
    preferential = base,
    fast
  ) |>
  gt::gt() |>
  gt::tab_spanner(
    label = "Walking speed (cm/s)",
    columns = c(slow, intermediate, preferential, fast)
  ) |>
  gt::cols_label(
    id = "ID",
    gender = "Gender",
    age = "Age range (years)",
    slow = "Slow",
    intermediate = "Intermediate",
    preferential = "Preferential",
    fast = "Fast"
  ) |>
  gt::sub_missing() |>
  gt::opt_stylize(style = 6, color = 'gray') |>
  gt::cols_align(align = "center") |>
  gt::tab_style(
    style = "vertical-align:top",
    locations = gt::cells_column_labels()
  )
```

## Data sets {#sec-data-sets}

### Sensor data

Raw data

: As mentioned before, the IMU sensor records the orientation of the device over time in the form of a unit QTS every 10 milliseconds. The four coordinates match the definition of a quaternion provided in @eq-quaternions. This data is stored in the list-column `bhg$egait`.

::: {.callout-tip title="The [{squat}](https://lmjl-alea.github.io/squat/) package"}
We developed a dedicated R package coined [{squat}](https://lmjl-alea.github.io/squat/) for **S**tatistics for **QUA**ternion **T**emporal Data which defines a specific data structure of class `qts` to store and manipulate unit QTS data. In particular, `bhg$egait` is a list of objects of class `qts` which stores the IMU sensor data that we collected. An object of class `qts` is a [tibble](https://tibble.tidyverse.org/) with five columns: a *time* column and four columns for the quaternion coordinates named *w*, *x*, *y* and *z*.
:::

We first need to filter out the initial three seconds of data where the subject is standing still before walking on the mat. This can be achieved using the `dplyr::filter()` function. For visualization purposes, we then implemented both a `graphics::plot()` and `ggplot2::autoplot()` S3 specializations for objects of class `qts` in [{squat}](https://cran.r-project.org/package=squat). Many other S3 specializations and methods for objects of class `qts` are available as explained in the dedicated website[^squat-website]. Below, we use the `autoplot` S3 specialization to produce @fig-raw-qts which shows an example of QTS from the data set `bhg`.

[^squat-website]: <https://lmjl-alea.github.io/squat/>.

```{r}
#| label: fig-raw-qts
#| fig-cap: "Raw data recorded by the IMU sensor as a 4-coordinate unit QTS."
#| fig-pos: "H"
bhg$egait <- lapply(
  bhg$egait,
  \(qts) {
    dplyr::filter(qts, time > 3)
  }
)
bhg$egait[[33]] |>
  autoplot() +
  theme_bw() +
  labs(title = "", x = "Time (seconds)")
```

It is important to observe that @fig-raw-qts displays the gait of a healthy person with nicely depicted gait cycles that are consistent over time. Impaired gait will not necessarily exhibit the same regularity.

Centered data

: A centring step is applied on the QTS to mitigate sensor shifts in position along the belt. This preprocessing step ensures that the mean quaternion of each QTS is the identity. In details, let $\mathbf{Q}_1, \dots, \mathbf{Q}_n$ be $n$ QTS observed on the same time grid $t_1 < t_2 < \dots < t_p$. Recall that we write $\mathbf{Q}_i(t_j) = \mathbf{q}_{ij} \in \mathbb{H}_u$, for any $i \in [\![ 1, n ]\!]$ and $j \in [\![ 1, p ]\!]$. We use the Fréchet mean associated to the geodesic distance $d_g$ (see @eq-geodesic-distance) to compute the mean $\mathbf{q}_j^{(m)}$ of all quaternions $\mathbf{q}_{1j}, \dots, \mathbf{q}_{nj}$ at a given time point $t_j$:

$$
\mathbf{q}_j^{(m)} = \underset{\mathbf{q} \in \mathbb{H}_u}{\mathrm{argmin}} \sum_{i=1}^n d_g^2(\mathbf{q}_{ij}, \mathbf{q}), \hspace{5mm} j \in [\![ 1, p ]\!].
$$ {#eq-mean-qts}

Numerically, @eq-mean-qts is solved iteratively following algorithms proposed in @moakher02 and @manton04. The centered QTS $\mathbf{Q}_1^{(c)}, \dots, \mathbf{Q}_n^{(c)}$ can then be computed as:

$$
\mathbf{q}_{ij}^{(c)} = \mathbf{Q}_i^{(c)} (t_j) = \left( \mathbf{q}_j^{(m)} \right)^{-1} \mathbf{q}_{ij}, \hspace{5mm} j \in [\![ 1, p ]\!],\hspace{2mm}  i \in [\![ 1, n ]\!].
$$ {#eq-centring-qts}

From a practical perspective, the centring step can be performed by applying the `squat::centring()` function to each element of the list-column `bhg$egait`:

```{r}
#| label: fig-centered-qts
#| fig-cap: "Raw data recorded by the IMU sensor after application of the centering step."
#| fig-pos: "H"
bhg$egait <- lapply(
  bhg$egait,
  \(qts) {
    squat::centring(qts)
  }
)
bhg$egait[[33]] |>
  autoplot() +
  theme_bw() +
  labs(title = "", x = "Time (seconds)")
```

@fig-centered-qts shows the same unit QTS as exhibited in @fig-raw-qts after the centring step. It has the effect of centering quaternions around the neutral element $(1,0,0,0)$ of the Lie group which is visible notably on the $w$ component.

B-spline representation

: The raw (or centered) QTS data recorded by the sensor can be noisy due to small movements of the sensor during walking or electronic noise. To reduce this noise, we applied a smoothing step on the centered QTS using cubic splines. This step requires to choose a smoothness parameter that controls the amount of smoothing applied to the original data. A higher value of this parameter results in a smoother QTS but may also remove relevant information. In details, we fit a smoothing cubic spline representation $\mathbf{v}_s$ to each component of the logarithm $\mathbf{v} = \ln \mathbf{q}(t)$ of the centered QTS independently using the `smooth.spline()` from the `R` {stats} package. The functional representation of the QTS itself is then obtained by exponentiating the smoothed logarithm back to the unit quaternion space which reads:

$$
\mathbf{q}_s (t) = \exp \mathbf{v}_s (t), \text{ where } \mathbf{v}(t) = \ln \mathbf{q}(t).
$$ {#eq-smoothed-qts}

We used the default settings of the `stats::smooth.spline()` function except for the *spar* parameter which we tuned as a hyper-parameter (see @sec-feature-space). The code below shows the steps required to perform the smoothing step for a given value of the *spar* parameter:

```{r}
#| label: fig-smoothed-qts
#| fig-cap: "Smoothed version of a centered QTS."
#| fig-pos: "H"
spar <- 0.3 # example value for the spar parameter
log_qts <- log(bhg$egait[[33]])
smoothed_log_qts <- as_qts(dplyr::tibble(
  time = log_qts$time,
  w = 0,
  x = stats::smooth.spline(log_qts$time, log_qts$x, spar = spar)$y,
  y = stats::smooth.spline(log_qts$time, log_qts$y, spar = spar)$y,
  z = stats::smooth.spline(log_qts$time, log_qts$z, spar = spar)$y
))
smoothed_qts <- exp(smoothed_log_qts)
smoothed_qts |>
  autoplot() +
  theme_bw() +
  labs(title = "", x = "Time (seconds)")
```

The code above illustrates some other nice S3 specializations implemented in the [{squat}](https://cran.r-project.org/package=squat/) package such as the `log()` and `exp()` functions to compute the logarithm and exponential of a unit QTS respectively. As mentioned in @sec-quaternions, the logarithm of a unit quaternion has a null scalar part, which is why we set the *w* coordinate to zero in the code above and only smooth the three other coordinates. The function `squat::qts2sqts()` is dedicated to performing this exact computation. @fig-smoothed-qts nicely shows the smoothing effect with subtle variations along the curves that are smoothed out.

### Pressure mat data {#sec-gaitrite-data}

The GAITRite® mat records the positions of the feet on the mat through pressure-sensitive sensors hidden beneath the mat. It returns a table of spatio-temporal parameters such as stride duration, stride length, walking speed, etc. @tbl-gaitrite-params in the Appendix provides the exhaustive list of all spatio-temporal gait parameters that the walkway outputs. It also returns the time of each event happening during a gait cycle such as the time where a foot touches or leaves the ground. These are the times we use to label our data to predict these events. Since the two devices were triggered simultaneously, the IMU sensor and the GAITRite® mat are assumed to share the same time clock. We use the pressure mat as a gold standard to label the observations into the different classes and train models on this labeled data.

As described in @sec-introduction and nicely summarized in @fig-walking-cycle, the gait events of interest are :

- *Right Heel Strike* (RHS) which corresponds to the moment when the right foot touches the ground for the first type;
- *Left Toe Off* (LTO) which corresponds to the moment when the left foot leaves the ground entirely;
- *Left Heel Strike* (LHS) which corresponds to the moment when the left foot touches the ground for the first type;
- *Right Toe Off* (RTO) which corresponds to the moment when the right foot leaves the ground entirely.

From these events, one can define phases within the gait cycle as follows:

- *Pre-Stance* phase: timespan between two consecutive RHS and LTO events;
- *Stance* phase: timespan between two consecutive LTO and LHS events;
- *Pre-Swing* phase: timespan between two consecutive LHS and RTO events;
- *Swing* phase: timespan between two consecutive RTO and RHS events.

The part of the raw data from the GAITRite® walkway that we kept for labeling the data is made of three variables:

```{r}
#| label: tbl-gaitrite
#| tbl-cap: "An illustration (33rd session) of the subset of GAITRite data used for detecting the key events for gait segmentation."
#| tbl-pos: "H"
bhg$gaitrite[[33]] |>
  dplyr::select(foot, first_contact, last_contact) |>
  gt::gt() |>
  gt::cols_label(
    foot = "Foot",
    first_contact = "First Contact (s)",
    last_contact = "Last Contact (s)"
  ) |>
  gt::opt_stylize(style = 6, color = 'gray') |>
  gt::cols_align(align = "center") |>
  gt::tab_style(
    style = "vertical-align:top",
    locations = gt::cells_column_labels()
  )
```

@tbl-gaitrite describes each occurence of a foot (`foot`: 0 for left foot, 1 for right foot) touching the ground, from the moment it touches it for the first time (`first_contact`) to the moment when it leaves it entirely (`last_contact`). Therefore, for instance, we can extract the RHS events by (i) filtering the table to keep only rows for which `foot == 1` and (ii) selecting the `first_contact` column which will contain exactly the times at which RHS events occured.

An additional preprocessing step is required as part of the synchronization between the GAITRite® and IMU devices. In effect, while we setup a procedure to optimize synchronization, the procedure is only precise up to 5/10 milliseconds. Furthermore, the two devices have different frequencies. Hence, we need to match timepoints measured by the GAITRite® device to the closest timepoint measured by the IMU device.

Another important data pre-processing step pertains to making sure that the retrieved events are ordered appropriately. In effect, by definition, RTO events should follow LHS events, which in turn should follow LTO events which in turn should follow RHS events. The pressure mat might make some labeling mistakes, notably at the beginning or at the end of the walking session, making this verification step critical.

Finally, with the aim of segmenting gait data into gait cycles in a streamlined fashion as the data is measured in real time, we will rely only on present and past data but not future data. Hence, we can filter out the data measured by the IMU device after the occurence of the last gait event of interest as it will not be used. Also, in the present work, we used data up to five timepoints back in time. Hence, we can also filter out all the data measured by the IMU device before the occurence of the first gait event of interest except for the 10 timepoints preceding that first event.

The following code achieves all the pre-processing steps described above and produces @fig-imu-gaitrite which shows events of interest overlaid on a unit QTS measured by the IMU device:

```{r}
#| label: fig-imu-gaitrite
#| fig-cap: "A unit QTS (33rd session) measured by the IMU device on which are overlaid the four events of interest detected by the GAITRite® device."
#| fig-pos: "H"
match_gaitrite_to_imu_timepoints <- function(
  gaitrite_timepoints,
  imu_timepoints
) {
  keep <- gaitrite_timepoints >= min(imu_timepoints)
  keep <- keep & gaitrite_timepoints <= max(imu_timepoints)
  gaitrite_timepoints <- gaitrite_timepoints[keep]
  sort(purrr::map_dbl(gaitrite_timepoints, \(gaitrite_timepoint) {
    idx <- which.min(abs(imu_timepoints - gaitrite_timepoint))
    imu_timepoints[idx]
  }))
}

# Read raw events of interest from
# gaitrite and match them to imu clock

rhs <- purrr::map2(bhg$gaitrite, bhg$egait, \(.gaitrite, .imu) {
  .gaitrite |>
    dplyr::filter(foot == 1) |>
    dplyr::pull(first_contact) |>
    match_gaitrite_to_imu_timepoints(imu_timepoints = .imu$time)
})

lto <- purrr::map2(bhg$gaitrite, bhg$egait, \(.gaitrite, .imu) {
  .gaitrite |>
    dplyr::filter(foot == 0) |>
    dplyr::pull(last_contact) |>
    match_gaitrite_to_imu_timepoints(imu_timepoints = .imu$time)
})

lhs <- purrr::map2(bhg$gaitrite, bhg$egait, \(.gaitrite, .imu) {
  .gaitrite |>
    dplyr::filter(foot == 0) |>
    dplyr::pull(first_contact) |>
    match_gaitrite_to_imu_timepoints(imu_timepoints = .imu$time)
})

rto <- purrr::map2(bhg$gaitrite, bhg$egait, \(.gaitrite, .imu) {
  .gaitrite |>
    dplyr::filter(foot == 1) |>
    dplyr::pull(last_contact) |>
    match_gaitrite_to_imu_timepoints(imu_timepoints = .imu$time)
})

# Make sure events of interest respect
# the order RHS --> LTO --> LHS --> RTO

gaitrite_data <- purrr::map(1:nrow(bhg), \(index) {
  out <- dplyr::bind_rows(
    tibble::tibble(
      event_time = rhs[[index]],
      event_type = rep("RHS", length(rhs[[index]]))
    ),
    tibble::tibble(
      event_time = lto[[index]],
      event_type = rep("LTO", length(lto[[index]]))
    ),
    tibble::tibble(
      event_time = lhs[[index]],
      event_type = rep("LHS", length(lhs[[index]]))
    ),
    tibble::tibble(
      event_time = rto[[index]],
      event_type = rep("RTO", length(rto[[index]]))
    )
  ) |>
    dplyr::arrange(event_time)
  phase_index <- 1
  out$phase <- rep(phase_index, nrow(out))
  for (i in 2:nrow(out)) {
    current_event <- out$event_type[i]
    previous_event <- out$event_type[i - 1]
    same_phase <- switch(
      current_event,
      "RHS" = previous_event == "RTO",
      "LTO" = previous_event == "RHS",
      "LHS" = previous_event == "LTO",
      "RTO" = previous_event == "LHS"
    )
    if (same_phase) {
      out$phase[i] <- phase_index
    } else {
      phase_index <- phase_index + 1
      out$phase[i] <- phase_index
    }
  }
  largest_phase_index <- out |>
    dplyr::count(phase) |>
    dplyr::pull(n) |>
    which.max()
  out |>
    dplyr::filter(phase == largest_phase_index) |>
    dplyr::select(-phase)
}) |>
  dplyr::bind_rows(.id = "session") |>
  dplyr::mutate(session = as.numeric(session))

# Filter out imu data collected after
# the last event of interest and before
# 10 points before the first event

t_min <- gaitrite_data |>
  dplyr::group_by(session) |>
  dplyr::summarise(event_time = min(event_time)) |>
  dplyr::pull(event_time)
t_max <- gaitrite_data |>
  dplyr::group_by(session) |>
  dplyr::summarise(event_time = max(event_time)) |>
  dplyr::pull(event_time)

imu_data <- purrr::pmap(list(bhg$egait, t_min, t_max), \(.imu, .t_min, .t_max) {
  idx_min <- which(.imu$time == .t_min)[1]
  idx_max <- which(.imu$time == .t_max)[1]
  lower_bnd <- max(idx_min - 10, 1)
  upper_bnd <- min(idx_max, nrow(.imu))
  .imu[lower_bnd:upper_bnd, ]
})

# Plot data from the 33rd session
# as an example

source("scripts/utils-viz.R")

gaitrite33 <- gaitrite_data[gaitrite_data$session == 33, ]
rhs33 <- gaitrite33 |>
  dplyr::filter(event_type == "RHS") |>
  dplyr::pull(event_time)
lto33 <- gaitrite33 |>
  dplyr::filter(event_type == "LTO") |>
  dplyr::pull(event_time)
lhs33 <- gaitrite33 |>
  dplyr::filter(event_type == "LHS") |>
  dplyr::pull(event_time)
rto33 <- gaitrite33 |>
  dplyr::filter(event_type == "RTO") |>
  dplyr::pull(event_time)
plot_ts(imu_data[[33]], rhs33, rto33, lhs33, lto33)
```

## Feature space {#sec-feature-space}

In this work, the objective is to identify which timepoints of unit QTS correspond to the RHS, LTO, LHS and RTO events. For this purpose, we consider the timepoints as statistical units (observations) and we aim at labelling them by means of supervised classification models. We therefore need to define a so-called *feature space* which consists of a data table listing the timepoints by row and collecting a number of features for each of them. A first important feature is the actual label that we want to predict with the trained model. @sec-labelled-gait-data details the elaboration of what

### Labelled gait data {#sec-labelled-gait-data}

 In this view, we can first create the data set that we will use for training. The following code achieves this task by binding together all timepoints from all walking sessions while attaching to each timepoint:

- an `event_type` which affects it to one of the five gait events defined in @sec-gaitrite-data;
- a `phase_type` which affects it one of the four gait pahses defined in @sec-gaitrite-data.

```{r}
events_to_phases <- function(events) {
  events_of_interest <- events != "None"
  first_event <- events[events_of_interest][1]
  phase_durations <- diff(c(0, sort(which(events_of_interest))))
  n_phases <- length(phase_durations)
  phase_names <- switch(
    first_event,
    "RHS" = rep(
      c("Swing", "Pre-Stance", "Stance", "Pre-Swing"),
      times = n_phases
    )[1:n_phases],
    "LTO" = rep(
      c("Pre-Stance", "Stance", "Pre-Swing", "Swing"),
      times = n_phases
    )[1:n_phases],
    "LHS" = rep(
      c("Stance", "Pre-Swing", "Swing", "Pre-Stance"),
      times = n_phases
    )[1:n_phases],
    "RTO" = rep(
      c("Pre-Swing", "Swing", "Pre-Stance", "Stance"),
      times = n_phases
    )[1:n_phases]
  )
  purrr::map2(
    phase_names,
    phase_durations,
    \(phase_name, phase_duration) rep(phase_name, times = phase_duration)
  ) |>
    purrr::list_c()
}

labelled_gait_data <- purrr::map(1:nrow(bhg), \(session_index) {
  gaitrite_data <- gaitrite_data |>
    dplyr::filter(session == session_index) |>
    dplyr::select(-session)
  imu_data[[session_index]] |>
    dplyr::left_join(gaitrite_data, by = c("time" = "event_time")) |>
    dplyr::mutate(
      event_type = dplyr::if_else(is.na(event_type), "None", event_type),
      phase_type = events_to_phases(event_type)
    )
}) |>
  dplyr::bind_rows(.id = "session") |>
  dplyr::mutate(
    session = as.numeric(session),
    event_type = factor(
      event_type,
      levels = c("RHS", "LTO", "LHS", "RTO", "None")
    ),
    phase_type = factor(
      phase_type,
      levels = c("Pre-Stance", "Stance", "Pre-Swing", "Swing")
    )
  )
class(labelled_gait_data) <- class(labelled_gait_data)[-1]
head(labelled_gait_data)
```

The feature space is an important piece of machine learning models as it defines the data that will be used to train them. In our application, we constructed a feature space from the raw QTS data recorded by the IMU sensor. First, we need to define what is an observation in our context. An observation corresponds to the data recorded at a given time point $t_j$. Since QTS are ordered sets of unit quaternions, for the $j$-*th* observation (row) of the feature space, we can then use features computed from the data observed at time $t_j$ or any other time points preceding $t_j$. One feature is of course the label of the observation that we get from the gold standard. This variable is available for the train/test process but will not be available at prediction time since it corresponds to the events that we want to predict. The other features are predictors that we compute from the sensor data. The ultimate goal is to design a feature space to label each observation $t_j$ with the gait event happening at that time (if any) using only the predictors computed from the QTS at time points $t_k \le t_j$, with $1 \le k \le j$. In the remainder of this section, we describe the predictors that we computed to build our feature space.

Angular velocity and acceleration vectors

: If we can have access to the first and second time derivatives of a QTS, we can compute the *angular velocity vector* $\pmb{\Omega}$ and *angular acceleration vector* $\dot{\pmb{\Omega}}$ [@narayan2017]. These vectors are aligned with the axis of rotation and carry in their norm the angular velocity and acceleration respectively. The angular velocity vector is computed as follows:

$$
\begin{bmatrix}
0 \\
\pmb{\Omega}
\end{bmatrix}
= 2 \mathbf{q}^{-1} \dot{\mathbf{q}} \hspace{3mm} \text{with} \hspace{3mm} \dot{\mathbf{q}} = \frac{d \mathbf{q}}{dt} = \frac{1}{2} \mathbf{q} \begin{bmatrix}
0 \\
\pmb{\Omega}
\end{bmatrix}.
$$ {#eq-angular-vel}

Recall that $\mathbf{q} = \exp \mathbf{v}$ where $\mathbf{v}$ is the logarithm of $\mathbf{q}$ introduced in @eq-smoothed-qts. Then, we have after simple mathematical computations that $\dot{\mathbf{q}} = \mathbf{q} \dot{\mathbf{v}}$. Therefore, the angular velocity vector is nothing but twice the vector part of the temporal derivative $\dot{\mathbf{v}}$ of the log-QTS. This is implemented in the `squat::qts2avvts()` function, which returns a tibble with columns `time`, `x`, `y` and `z` storing the coordinates of the angular velocity vector at each time point as illustrated by @fig-avvts:

```{r}
#| label: fig-avvts
#| fig-cap: "An illustration (33rd session) of the angular velocity vector time series representation."
#| fig-pos: "H"
avvts <- squat::qts2avvts(imu_data[[33]], spar = spar)
avvts |>
  dplyr::rename(`v[x]` = x, `v[y]` = y, `v[z]` = z) |>
  tidyr::pivot_longer(
    cols = c(`v[x]`, `v[y]`, `v[z]`),
    names_to = "component",
    values_to = "angular_velocity"
  ) |>
  ggplot(aes(x = time, y = angular_velocity)) +
  geom_line() +
  facet_wrap(~component, ncol = 1, scales = "free_y", labeller = label_parsed) +
  theme_bw() +
  labs(title = "", x = "Time (seconds)", y = "Angular velocity (rad/s)")
```

The angular acceleration vector $\dot{\pmb{\Omega}}$ is then computed as the derivative of the angular velocity vector:

$$
\begin{bmatrix}
0 \\
\dot{\pmb{\Omega}}
\end{bmatrix}
= 2 \left( \mathbf{q}^{-1} \ddot{\mathbf{q}} - (\mathbf{q}^{-1}\dot{\mathbf{q}})^2 \right) \hspace{3mm} \text{with} \hspace{3mm} \ddot{\mathbf{q}} = \frac{d^2 \mathbf{q}}{dt^2} = \frac{1}{2} \left( \dot{\mathbf{q}} \begin{bmatrix}
0 \\
\pmb{\Omega}
\end{bmatrix} + \mathbf{q} \begin{bmatrix}
0 \\
\dot{\pmb{\Omega}}
\end{bmatrix} \right)
$$ {#eq-angular-acc}

From $\dot{\mathbf{q}} = \mathbf{q} \dot{\mathbf{v}}$, we can write the second temporal derivative of $\mathbf{q}$ as $\ddot{\mathbf{q}} = \mathbf{q} \left( \dot{\mathbf{v}} \dot{\mathbf{v}} + \ddot{\mathbf{v}} \right)$. Therefore, the angular acceleration vector is nothing but twice the vector part of the second temporal derivative $\ddot{\mathbf{v}}$ of the log-QTS. This is implemented in the `squat::qts2aavts()` function, which returns a tibble with columns `time`, `x`, `y` and `z` storing the coordinates of the angular acceleration vector at each time point as illustrated by @fig-aavts:

```{r}
#| label: fig-aavts
#| fig-cap: "An illustration (33rd session) of the angular acceleration vector time series representation."
#| fig-pos: "H"
aavts <- squat::qts2aavts(imu_data[[33]], spar = spar)
aavts |>
  dplyr::rename(`a[x]` = x, `a[y]` = y, `a[z]` = z) |>
  tidyr::pivot_longer(
    cols = c(`a[x]`, `a[y]`, `a[z]`),
    names_to = "component",
    values_to = "angular_acceleration"
  ) |>
  ggplot(aes(x = time, y = angular_acceleration)) +
  geom_line() +
  facet_wrap(~component, ncol = 1, scales = "free_y", labeller = label_parsed) +
  theme_bw() +
  labs(title = "", x = "Time (seconds)", y = "Angular acceleration (rad/s²)")
```

Euler angles

: The angles named *Roll*, *Pitch* and *Yaw* represent rotations around the three principal axes. They are computed from a unit quaternion $\mathbf{q} = (q_w, q_x, q_y, q_z)$ using the following formulas:

$$
\begin{bmatrix}
\mathrm{Roll} \\
\mathrm{Pitch} \\
\mathrm{Yaw}
\end{bmatrix}
= 
\begin{bmatrix}
\arctan\!2 \left(2(q_w q_x + q_y q_z), 1-2(q_x^2 + q_y^2)  \right) \\
\arcsin \left(2(q_w q_y - q_x q_z) \right) \\
\arctan\!2 \left(2(q_w q_z + q_x q_y), 1-2(q_y^2 + q_z^2)  \right)
\end{bmatrix}
$$ {#eq-rpy}

where $\arctan\!2(y, x)$ computes the angle $\theta$ (in radians) between the positive $x$-axis and the ray from the origin to the point $(x, y)$ in the Cartesian plane. This is implemented in the `squat::qts2rpyts()` function, which returns a tibble with columns `time`, `roll`, `pitch` and `yaw` storing the roll, pitch and yaw angles at each time point as illustrated by @fig-rpyts:

```{r}
#| label: fig-rpyts
#| fig-cap: "An illustration (33rd session) of the roll-pitch-yaw time series representation."
#| fig-pos: "H"
rpyts <- squat::qts2rpyts(imu_data[[33]])
rpyts |>
  dplyr::rename(Roll = roll, Pitch = pitch, Yaw = yaw) |>
  tidyr::pivot_longer(
    cols = c(Roll, Pitch, Yaw),
    names_to = "component",
    values_to = "angle_values"
  ) |>
  ggplot(aes(x = time, y = angle_values)) +
  geom_line() +
  facet_wrap(~component, ncol = 1, scales = "free_y", labeller = label_parsed) +
  theme_bw() +
  labs(title = "", x = "Time (seconds)", y = "Angle (rad)")
```

Walking speed

: It is likely that the shape of the QTS can be quite different according to the walking speed. We therefore included this information in the feature space from the GAITRite® mat output. Since this predictor comes from the gold standard, it is not available when predicting on new time series where patients only used the wearable sensor. To counter this issue, we can estimate the walking speed from the mean angular velocity with a simple linear regression.

Hyper-parameters

: The feature space depends on a number of hyper-parameters. The first one is a smoothness parameter called *spar* that represents the amount of smoothing that we seek to achieve when fitting cubic splines to the original QTS. Since time derivatives are used to compute some predictors, it is indeed useful to smooth the QTS sufficiently so the derivative values remain stable and not dominated by noise. The *spar* parameter takes its values in the interval $]0,1]$. The second hyper-parameter is the *lag* parameter. To keep information from the past as we predict at a given time point $t_j$, we include features computed at $t_j$ as well as the same features computed at time points $t_{j-1}, \dots, t_{j-\mathrm{lag}}$. The size of the feature space therefore depends on the *lag* parameter as it contains $10 + 9 \times \mathrm{lag}$ predictors. The ten first predictors are the three-component angular speed vector, the three-component angular acceleration vector, the three angles Roll, Pitch and Yaw and the walking speed. We then add nine predictors per *lag*: the angular speed and acceleration and the Roll-Pitch-Yaw angles from the previous time.

Finally, a last hyper-parameter is used when we label the observations with the gait event times from the gold standard. It is called *k* and controls the number of points around a gait event that we label as part of the event. In @sec-classification-strategies, we elicit two strategies for building segmentation models, one of which does not use this parameter. Therefore, we differ other details about this parameter in the dedicated section.