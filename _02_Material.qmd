# Material {#sec-material}

This section is dedicated to describing the data that we used for segmenting gait in the present work. Essentially, we used two sources of data. First, we clipped a 9-axis inertial measurement unit (IMU) sensor at the level of the right hip and measured its orientation (that we assimilate to the hip orientation) over time during walking sessions. The data is recorded in the form of a unit quaternion time series. @sec-quaternions provides a brief overview of unit quaternions and their properties. Second, we used a pressure-sensitive walkway (GAITRite® mat) as a gold standard to label the gait events. @sec-data-acquisition elicits the data acquisition protocol while @sec-data-sets summarizes the two data sets. Finally, @sec-feature-space details the feature space that we constructed from the raw data to feed our machine learning models.

## Unit quaternions {#sec-quaternions}

Unit quaternions can be used to represent the 3D rotation of an object over time [@hamilton1844;@voight2021quaternion]. This representation has several advantages such as being the most compressed representation of rotation and avoiding the gimbal lock issue. We therefore chose to measure the sensor orientation as a unit quaternion.

Quaternions are four-dimensional vectors denoted by $\mathbf{q} = \left( q_w, q_x, q_y, q_z \right)$, but can also be viewed as hypercomplex numbers of rank $4$. Unit quaternions have a norm of $1$ and encode a 3D rotation with rotation angle $\theta \in [0, 2\pi]$ and rotation axis $\mathbf{u} = (u_x, u_y, u_z) \in S^2$, where $S^2$ is the 2-sphere, using the following formula:

$$
\mathbf{q} = \left( q_w, q_x, q_y, q_z \right)
= \cos \left( \frac{\theta}{2} \right) + \left( u_x i + u_y j + u_z k \right) \cdot \sin \left( \frac{\theta}{2} \right),
$$ {#eq-quaternions}

where $i$, $j$, and $k$ generalize the imaginary number $i$ and are such that $i^2 = j^2 = k^2 = ijk = -1$. Note that it is straightforward to show quaternions define through @eq-quaternions have unit norm.

The set of unit quaternions, denoted by $\mathbb{H}_u$, has a number of interesting properties. First, the quaternions $\mathbf{q}$ and $-\mathbf{q}$ represent the same rotation making $\mathbb{H}_u$ a double coverage of the space $\mathrm{SO}_3(\mathbb{R})$ of 3D rotations. Also, $\mathbb{H}_u$ forms a Lie group which is a group and a differentiable Riemannian manifold. As a group, it is in particular equipped with an identity element $\mathbf{q}^{(0)} = (1,0,0,0)$ which corresponds to the identity rotation, such that, for any $\mathbf{q} \in \mathbb{H}_u$, we have $\mathbf{q} \mathbf{q}^{(0)} = \mathbf{q}^{(0)}\mathbf{q} = \mathbf{q}$ and with a composition law $\circ$ given by the Hamilton product:

$$
\begin{aligned}
\mathbf{q}_1 \circ \mathbf{q}_2 = ( &q_{1w} q_{2w} - q_{1x} q_{2x} - q_{1y} q_{2y} - q_{1z} q_{2z}, \\
&q_{1w} q_{2x} + q_{1x} q_{2w} + q_{1y} q_{2z} - q_{1z} q_{2y}, \\
&q_{1w} q_{2y} - q_{1x} q_{2z} + q_{1y} q_{2w} + q_{1z} q_{2x}, \\
&q_{1w} q_{2z} + q_{1x} q_{2y} - q_{1y} q_{2x} + q_{1z} q_{2w}).
\end{aligned}
$$ {#eq-hamilton-product}

This is known as quaternion multiplication and, for simplicity, the symbol $\circ$ is often omitted and we simply write $\mathbf{q}_1 \mathbf{q}_2$. Note that the composition law is not commutative. As such, $\mathbb{H}_u$ is an Abelian group. The inverse of a unit quaternion $\mathbf{q}$ is given by its conjugate $\mathbf{q}^{-1} = \mathbf{q}^\star = (q_w, -q_x, -q_y, -q_z)$.

As a differentiable Riemannian manifold, it is also equipped with a natural distance, known as the *geodesic distance*, that can be used to measure the distance between two unit quaternions. For any two quaternions $\mathbf{q}_1$ and $\mathbf{q}_2$, it reads:

$$
d_g \left( \mathbf{q}_1, \mathbf{q}_2 \right) = \left\| \ln \left( \mathbf{q}_1^{-1} \mathbf{q}_2 \right) \right\| = \arccos \left( 2 \left( \mathbf{q}_1 \cdot \mathbf{q}_2 \right)^2 -1 \right),
$$ {#eq-geodesic-distance}

where the unit quaternion logarithm is defined as $\ln(\mathbf{q}) = \mathbf{u} \dfrac{\theta}{2}$.

In our application, the sensor orientation is the rotation between the reference frame of origin, here the Earth's reference frame $R_f=(f_1, f_2, f_3)$ and its own reference frame $R_s=(s_1, s_2, s_3)$ formed by the accelerometer, gyroscope, and magnetometer (see @fig-sensor-axis).

![Sensor reference and axis. [@drouin2023semi]](images/sensor-axis.png){#fig-sensor-axis width=200}

A *quaternion time series* (QTS) is an ordered set $\mathbf{Q}$ of unit quaternions along a temporal grid $t_1 < t_2 < \dots < t_p$. We will denote by $\mathbf{q}_{j} = \mathbf{Q}(t_j)$ the unit quaternion of the QTS $\mathbf{Q}$ recorded at time $t_j$. In our application, it represents the orientation of the hip at that time.

## Data acquisition {#sec-data-acquisition}

We used an IMU sensor to record the hip orientation over time. The IMU was composed of a 3-axis accelerometer, a 3-axis gyroscope and a 3-axis magnetometer. Subjects were wearing the sensor on their right hip (see @fig-sensor-position). The frequency of the sensor is $100$ Hz which corresponds to recording its orientation every $10$ ms. With this device, the data acquired is in the form of unit QTS as presented in @sec-quaternions.

![Sensor positionned on the right hip.](images/sensor-position.png){#fig-sensor-position width=150}

We asked the participants to walk on the GAITRite® mat, a gold standard in gait analysis [@Menz2004] while wearing the IMU sensor on their right hip. This choice, required to have a labeling of gait events from the walkway, constrained the path followed by the participants to a straight line of approximately nine meters. The GAITRite® device gives various information thanks to pressure sensors contained in the mat such as the time points where the subject feet touch and leave the ground at each step, which are exactly the gait events of interest to train our segmentation models for the IMU sensor. To use the two devices simultaneously, they were started at the same time by the same person with their two index fingers, allowing a good synchronization between devices [@de1992stability]. Also, we asked the participants to wait for three seconds before starting to walk on the mat to ensure that the sensor was properly calibrated and stable before walking.

We included six subjects in this study (three men and three women) of different ages and walking at different speeds to have a variety of gait data. @tbl-subjects summarized the demographic characteristics of the participants. We recorded a total of 174 walking sessions between June and September 2024. The data is publicly available[^bhg-dataset]. We can therefore download it and store it in an R object for use in the rest of this document.

[^bhg-dataset]: <https://zenodo.org/records/18222246>.

::: {#tbl-subjects tbl-pos="H"}

```{r}
bhg <- readRDS(url(
  "https://zenodo.org/records/18222246/files/bellier_healthy_gait.rds?download=1"
))

bhg |>
  dplyr::group_by(subject, gender, age, condition) |>
  dplyr::summarise(speed = round(mean(speed), digits = 0), .groups = "drop") |>
  tidyr::pivot_wider(names_from = condition, values_from = speed) |>
  janitor::clean_names() |>
  dplyr::select(
    id = subject,
    gender,
    age,
    slow,
    intermediate,
    preferential = base,
    fast
  ) |>
  gt::gt() |>
  gt::tab_spanner(
    label = "Walking speed (cm/s)",
    columns = c(slow, intermediate, preferential, fast)
  ) |>
  gt::cols_label(
    id = "ID",
    gender = "Gender",
    age = "Age range (years)",
    slow = "Slow",
    intermediate = "Intermediate",
    preferential = "Preferential",
    fast = "Fast"
  ) |>
  gt::sub_missing() |>
  gt::opt_stylize(style = 6, color = 'gray') |>
  gt::cols_align(align = "center") |>
  gt::tab_style(
    style = "vertical-align:top",
    locations = gt::cells_column_labels()
  )
```

Summary of subjects and walking speeds used to train the model.

:::

## Data sets {#sec-data-sets}

### Sensor data

Raw data

: As mentioned before, the IMU sensor records the orientation of the device over time in the form of a unit QTS every 10 milliseconds. The four coordinates match the definition of a quaternion provided in @eq-quaternions. This data is stored in the list-column `bhg$egait`.

::: {.callout-tip title="The [{squat}](https://lmjl-alea.github.io/squat/) package"}
We developed a dedicated R package coined [{squat}](https://lmjl-alea.github.io/squat/) for **S**tatistics for **QUA**ternion **T**emporal Data which defines a specific data structure of class `qts` to store and manipulate unit QTS data. In particular, `bhg$egait` is a list of objects of class `qts` which stores the IMU sensor data that we collected. An object of class `qts` is a [tibble](https://tibble.tidyverse.org/) with five columns: a *time* column and four columns for the quaternion coordinates named *w*, *x*, *y* and *z*.
:::

We first need to filter out the initial three seconds of data where the subject is standing still before walking on the mat. This can be achieved using the `dplyr::filter()` function. For visualization purposes, we then implemented both a `graphics::plot()` and `ggplot2::autoplot()` S3 specializations for objects of class `qts` in [{squat}](https://cran.r-project.org/package=squat). Many other S3 specializations and methods for objects of class `qts` are available as explained in the dedicated website[^squat-website]. Below, we use the `autoplot` S3 specialization to produce @fig-raw-qts which shows an example of QTS from the data set `bhg`.

[^squat-website]: <https://lmjl-alea.github.io/squat/>.

::: {#fig-raw-qts fig-pos="H"}

```{r}
bhg$egait <- lapply(
  bhg$egait,
  \(qts) {
    dplyr::filter(qts, time > 3)
  }
)
bhg$egait[[33]] |>
  autoplot() +
  theme_bw() +
  labs(title = "", x = "Time (seconds)")
```

Raw data recorded by the IMU sensor as a 4-coordinate unit QTS.

:::

It is important to observe that @fig-raw-qts displays the gait of a healthy person with nicely depicted gait cycles that are consistent over time. Impaired gait will not necessarily exhibit the same regularity.

Centered data

: A centring step is applied on the QTS to mitigate sensor shifts in position along the belt. This preprocessing step ensures that the mean quaternion of each QTS is the identity. In details, let $\mathbf{Q}_1, \dots, \mathbf{Q}_n$ be $n$ QTS observed on the same time grid $t_1 < t_2 < \dots < t_p$. Recall that we write $\mathbf{Q}_i(t_j) = \mathbf{q}_{ij} \in \mathbb{H}_u$, for any $i \in [\![ 1, n ]\!]$ and $j \in [\![ 1, p ]\!]$. We use the Fréchet mean associated to the geodesic distance $d_g$ (see @eq-geodesic-distance) to compute the mean $\mathbf{q}_j^{(m)}$ of all quaternions $\mathbf{q}_{1j}, \dots, \mathbf{q}_{nj}$ at a given time point $t_j$:

$$
\mathbf{q}_j^{(m)} = \underset{\mathbf{q} \in \mathbb{H}_u}{\mathrm{argmin}} \sum_{i=1}^n d_g^2(\mathbf{q}_{ij}, \mathbf{q}), \hspace{5mm} j \in [\![ 1, p ]\!].
$$ {#eq-mean-qts}

Numerically, @eq-mean-qts is solved iteratively following algorithms proposed in @moakher02 and @manton04. The centered QTS $\mathbf{Q}_1^{(c)}, \dots, \mathbf{Q}_n^{(c)}$ can then be computed as:

$$
\mathbf{q}_{ij}^{(c)} = \mathbf{Q}_i^{(c)} (t_j) = \left( \mathbf{q}_j^{(m)} \right)^{-1} \mathbf{q}_{ij}, \hspace{5mm} j \in [\![ 1, p ]\!],\hspace{2mm}  i \in [\![ 1, n ]\!].
$$ {#eq-centring-qts}

From a practical perspective, the centring step can be performed by applying the `squat::centring()` function to each element of the list-column `bhg$egait`:

::: {#fig-centered-qts fig-pos="H"}

```{r}
bhg$egait <- lapply(
  bhg$egait,
  \(qts) {
    squat::centring(qts)
  }
)
bhg$egait[[33]] |>
  autoplot() +
  theme_bw() +
  labs(title = "", x = "Time (seconds)")
```

Raw data recorded by the IMU sensor after application of the centering step.

:::

@fig-centered-qts shows the same unit QTS as exhibited in @fig-raw-qts after the centring step. It has the effect of centering quaternions around the neutral element $(1,0,0,0)$ of the Lie group which is visible notably on the $w$ component.

B-spline representation

: The raw (or centered) QTS data recorded by the sensor can be noisy due to small movements of the sensor during walking or electronic noise. To reduce this noise, we applied a smoothing step on the centered QTS using cubic splines. This step requires to choose a smoothness parameter that controls the amount of smoothing applied to the original data. A higher value of this parameter results in a smoother QTS but may also remove relevant information. In details, we fit a smoothing cubic spline representation separately to each component of the logarithm of the centered QTS using the `smooth.spline()` from the R {stats} package. The functional representation of the QTS itself is then obtained by exponentiating the smoothed logarithm back to the unit quaternion space. We used the default settings of the `stats::smooth.spline()` function except for the *spar* parameter which we tuned as a hyper-parameter (see @sec-feature-space). The code below shows the steps required to perform the smoothing step for a given value of the *spar* parameter:

::: {#fig-smoothed-qts fig-pos="H"}

```{r}
spar <- 0.3 # example value for the spar parameter
log_qts <- log(bhg$egait[[33]])
smoothed_log_qts <- as_qts(dplyr::tibble(
  time = log_qts$time,
  w = 0,
  x = stats::smooth.spline(log_qts$time, log_qts$x, spar = spar)$y,
  y = stats::smooth.spline(log_qts$time, log_qts$y, spar = spar)$y,
  z = stats::smooth.spline(log_qts$time, log_qts$z, spar = spar)$y
))
smoothed_qts <- exp(smoothed_log_qts)
smoothed_qts |>
  autoplot() +
  theme_bw() +
  labs(title = "", x = "Time (seconds)")
```

Smoothed version of a centered QTS.
:::

The code above illustrates some other nice S3 specializations implemented in the [{squat}](https://cran.r-project.org/package=squat/) package such as the `log()` and `exp()` functions to compute the logarithm and exponential of a unit QTS respectively. As mentioned in @sec-quaternions, the logarithm of a unit quaternion has a null scalar part, which is why we set the *w* coordinate to zero in the code above and only smooth the three other coordinates. @fig-smoothed-qts nicely shows the smoothing effect with subtle variations along the curves that are smoothed out.

### Pressure mat data

The GAITRite® mat records the positions of the feet on the mat through pressure-sensitive sensors hidden beneath the mat. It returns a table of spatio-temporal parameters such as stride duration, stride length, walking speed, etc. @tbl-gaitrite-params in the Appendix provides the exhaustive list of all spatio-temporal gait parameters that the walkway outputs. It also returns the time of each event happening during a gait cycle such as the time where a foot touches or leaves the ground. These are the times we use to label our data to predict these events. Since the two devices were triggered simultaneously, the IMU sensor and the GAITRite® mat are assumed to share the same time clock. We use the pressure mat as a gold standard to label the observations between the different classes and train models on this labeled data.

## Feature space {#sec-feature-space}

The feature space is an important piece of machine learning models as it defines the data that will be used to train them. In our application, we constructed a feature space from the raw QTS data recorded by the IMU sensor. First, we need to define what is an observation in our context. An observation corresponds to the data recorded at a given time point $t_j$. Since QTS are ordered sets of unit quaternions, for the $j$-*th* observation (row) of the feature space, we can then use features computed from the data observed at time $t_j$ or any other time points preceding $t_j$. One feature is of course the label of the observation that we get from the gold standard. This variable is available for the train/test process but will not be available at prediction time since it corresponds to the events that we want to predict. The other features are predictors that we compute from the sensor data. The ultimate goal is to design a feature space to label each observation $t_j$ with the gait event happening at that time (if any) using only the predictors computed from the QTS at time points $t_k \le t_j$, with $1 \le k \le j$. In the remainder of this section, we describe the predictors that we computed to build our feature space.

Angular velocity and acceleration vectors

: If we can have access to the first and second time derivatives of a QTS, we can compute the *angular velocity vector* $\pmb{\Omega}$ and *angular acceleration vector* $\dot{\pmb{\Omega}}$ [@narayan2017]. These vectors are aligned with the axis of rotation and carry in their norm the angular velocity and acceleration respectively. The angular velocity vector is computed as follows:

$$
\begin{bmatrix}
0 \\
\pmb{\Omega}
\end{bmatrix}
= 2 \mathbf{q}^{-1} \dot{\mathbf{q}} \hspace{3mm} \text{with} \hspace{3mm} \dot{\mathbf{q}} = \frac{d \mathbf{q}}{dt} = \frac{1}{2} \mathbf{q} \begin{bmatrix}
0 \\
\pmb{\Omega}
\end{bmatrix}.
$$ {#eq-angular-vel}

The angular acceleration vector $\dot{\pmb{\Omega}}$ is then computed as the derivative of the angular velocity vector:

$$
\begin{bmatrix}
0 \\
\dot{\pmb{\Omega}}
\end{bmatrix}
= 2 \left( \mathbf{q}^{-1} \ddot{\mathbf{q}} - (\mathbf{q}^{-1}\dot{\mathbf{q}})^2 \right) \hspace{3mm} \text{with} \hspace{3mm} \ddot{\mathbf{q}} = \frac{d^2 \mathbf{q}}{dt^2} = \frac{1}{2} \left( \dot{\mathbf{q}} \begin{bmatrix}
0 \\
\pmb{\Omega}
\end{bmatrix} + \mathbf{q} \begin{bmatrix}
0 \\
\dot{\pmb{\Omega}}
\end{bmatrix} \right)
$$ {#eq-angular-acc}

Euler angles

: The angles named *Roll*, *Pitch* and *Yaw* represent rotations around the three principal axes. They are computed from a unit quaternion $\mathbf{q} = (q_w, q_x, q_y, q_z)$ using the following formulas:

$$
\begin{bmatrix}
\mathrm{Roll} \\
\mathrm{Pitch} \\
\mathrm{Yaw}
\end{bmatrix}
= 
\begin{bmatrix}
\arctan\!2 \left(2(q_w q_x + q_y q_z), 1-2(q_x^2 + q_y^2)  \right) \\
\arcsin \left(2(q_w q_y - q_x q_z) \right) \\
\arctan\!2 \left(2(q_w q_z + q_x q_y), 1-2(q_y^2 + q_z^2)  \right)
\end{bmatrix}
$$ {#eq-rpy}

where $\arctan\!2(y, x)$ computes the angle $\theta$ (in radians) between the positive $x$-axis and the ray from the origin to the point $(x, y)$ in the Cartesian plane.

Walking speed

: It is likely that the shape of the QTS can be quite different according to the walking speed. We therefore included this information in the feature space from the GAITRite® mat output. Since this predictor comes from the gold standard, it is not available when predicting on new time series where patients only used the wearable sensor. To counter this issue, we can estimate the walking speed from the mean angular velocity with a simple linear regression.


Hyper-parameters

: The feature space depends on a number of hyper-parameters. The first one is a smoothness parameter called *spar* that represents the amount of smoothing that we seek to achieve when fitting cubic splines to the original QTS. Since time derivatives are used to compute some predictors, it is indeed useful to smooth the QTS sufficiently so the derivative values remain stable and not dominated by noise. The *spar* parameter takes its values in the interval $]0,1]$. The second hyper-parameter is the *lag* parameter. To keep information from the past as we predict at a given time point $t_j$, we include features computed at $t_j$ as well as the same features computed at time points $t_{j-1}, \dots, t_{j-\mathrm{lag}}$. The size of the feature space therefore depends on the *lag* parameter as it contains $10 + 9 \times \mathrm{lag}$ predictors. The ten first predictors are the three-component angular speed vector, the three-component angular acceleration vector, the three angles Roll, Pitch and Yaw and the walking speed. We then add nine predictors per *lag*: the angular speed and acceleration and the Roll-Pitch-Yaw angles from the previous time.

Finally, a last hyper-parameter is used when we label the observations with the gait event times from the gold standard. It is called *k* and controls the number of points around a gait event that we label as part of the event. In @sec-classification-strategies, we elicit two strategies for building segmentation models, one of which does not use this parameter. Therefore, we differ other details about this parameter in the dedicated section.